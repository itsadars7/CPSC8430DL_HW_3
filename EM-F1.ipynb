{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8877df-a71f-40a2-89bc-8b469d3bd1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarshn/.local/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match (EM): 60.04485142963932\n",
      "F1 Score: 69.56580173817838\n",
      "Saved EM/F1 to outputs_spoken_squad_1.1/metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Compute EM/F1 from saved predictions in outputs_spoken_squad_1.1\n",
    "\n",
    "import os, json\n",
    "import evaluate\n",
    "\n",
    "OUTPUT_DIR = \"outputs_spoken_squad_1.1\"\n",
    "PRED_PATH  = os.path.join(OUTPUT_DIR, \"predictions.json\")\n",
    "TEST_FILE  = \"spoken_test-v1.1.json\"   \n",
    "\n",
    "def _flat_answers(ans):\n",
    "    texts  = ans.get(\"text\", [])\n",
    "    starts = ans.get(\"answer_start\", [])\n",
    "    if not isinstance(texts, list):  texts = [texts]\n",
    "    if not isinstance(starts, list): starts = [starts]\n",
    "    if texts and isinstance(texts[0], list):\n",
    "        texts = [t for sub in texts for t in sub]\n",
    "    if starts and isinstance(starts[0], list):\n",
    "        starts = [s for sub in starts for s in sub]\n",
    "    n = min(len(texts), len(starts))\n",
    "    return {\n",
    "        \"text\": [str(t) for t in texts[:n]],\n",
    "        \"answer_start\": [int(s) for s in starts[:n]],\n",
    "    }\n",
    "\n",
    "def load_references_from_test_json(path):\n",
    "    \"\"\"Load references (id, answers) from Spoken-SQuAD v1.1 test JSON.\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        j = json.load(f)\n",
    "    refs = []\n",
    "    for article in j.get(\"data\", []):\n",
    "        for para in article.get(\"paragraphs\", []):\n",
    "            for qa in para.get(\"qas\", []):\n",
    "                ex_id = str(qa.get(\"id\"))\n",
    "                ans   = qa.get(\"answers\", []) or []\n",
    "                texts  = [a.get(\"text\", \"\") for a in ans]\n",
    "                starts = [a.get(\"answer_start\", 0) for a in ans]\n",
    "                refs.append({\"id\": ex_id, \"answers\": _flat_answers({\"text\": texts, \"answer_start\": starts})})\n",
    "    return refs\n",
    "\n",
    "# load predictions and references\n",
    "with open(PRED_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    pred_text = json.load(f)  \n",
    "\n",
    "references = load_references_from_test_json(TEST_FILE)\n",
    "\n",
    "formatted_preds = [{\"id\": r[\"id\"], \"prediction_text\": pred_text.get(r[\"id\"], \"\")} for r in references]\n",
    "\n",
    "# compute metrics \n",
    "squad_metric = evaluate.load(\"squad\")  \n",
    "metrics = squad_metric.compute(predictions=formatted_preds, references=references)\n",
    "print(\"Exact Match (EM):\", metrics.get(\"exact_match\"))\n",
    "print(\"F1 Score:\", metrics.get(\"f1\"))\n",
    "\n",
    "# Save metrics \n",
    "with open(os.path.join(OUTPUT_DIR, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Saved EM/F1 to {os.path.join(OUTPUT_DIR, 'metrics.json')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecd900-599a-4144-8147-f82eb966b349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
